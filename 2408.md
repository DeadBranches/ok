2024-8-19 
arXiv:2408.08435v1 [cs.AI] 15 Aug 2024 
Automated Design of Agentic Systems 
Shengran Hu1,2, Cong Lu1,2 and Jeff Clune1,2,3 1University of British Columbia, 2Vector Institute, 3Canada CIFAR AI Chair 
Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We formulate a new research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, control flows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity. 
https://github.com/ShengranHu/ADAS 

1. Introduction 
Foundation Models (FMs) such as GPT (OpenAI, 2022, 2024) and Claude (Anthropic, 2024b) arequickly being adopted as powerful general-purpose agents for agentic tasks that need flexible reasoningand planning (Wang et al., 2024). Despite recent advancements in FMs, solving problems reliablyoften requires an agent to be a compound agentic system with multiple components instead of amonolithic model query (Rocktäschel, 2024; Zaharia et al., 2024). Additionally, to enable agents tosolve complex real-world tasks, they often need access to external tools such as search engines, codeexecution, and database queries. As a result, many effective building blocks of agentic systems havebeen proposed, such as chain-of-thought planning and reasoning (Hu & Clune, 2024; Wei et al., 2022; Yao et al., 2023), memory structures (Lewis et al., 2020; Zhang et al., 2024c), tool use (Qu et al., 2024; Schick et al., 2023), and self-reflection (Madaan et al., 2024; Shinn et al., 2023). Although these agents have already seen significant success across various applications (Wang et al., 2024),developing these building blocks and combining them into complex agentic systems often requiresdomain-specific manual tuning and substantial effort from both researchers and engineers. 
However, the history of machine learning reveals a recurring theme: manually created artifacts become replaced by learned, more efficient solutions over time as we get more compute anddata (Clune, 2019). An early example is from computer vision, where hand-designed features like HOG (Dalal & Triggs, 2005) were eventually replaced by learned features from Convolutional Neural Networks (CNNs, Krizhevsky et al. (2012)). More recently, AutoML methods (Hutter et al., 2019)and AI-Generating Algorithms (AI-GAs, Clune (2019)) have also demonstrated the superiority oflearned AI systems compared to hand-designed AI systems. For example, the current best-performingCNN models come from Neural Architecture Search (Elsken et al., 2019; Shen et al., 2023) instead of manual design; in LLM alignment, learned loss functions (Lu et al., 2024a) outperform most hand-designed ones such as DPO (Rafailov et al., 2024); The AI Scientist (Lu et al., 2024b) demonstrates an automated research pipeline, including the development of novel ML algorithms; andan endless number of robotics learning environments can be automatically generated in works likeOMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environmentsand allow more efficient environment creation than the manual approach (see more examples inSection 5). Therefore, in this paper, we propose a new research question: Can we automate the design of agentic systems rather than relying on manual efforts?

Figure 1 | Overview of the proposed algorithm Meta Agent Search and examples of discovered agents. In our algorithm, we instruct the “meta” agent to iteratively program new agents, test theirperformance on tasks, add them to an archive of discovered agents, and use this archive to inform themeta agent in subsequent iterations. We show three example agents across our runs, with all namesgenerated by the meta agent. The detailed code of example agents can be found in Appendix F. 

To explore the above research question, we formulate a new research area we call Automated Design of Agentic Systems (ADAS), which aims to automatically invent novel building blocks anddesign powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path todeveloping powerful agents, and show initial evidence that learned agents can greatly outperformhand-designed agents. Considering the tremendous number of building blocks yet to be discovered inagentic systems (Section 5), it would take a long time for our research community to discover themall. Even if we successfully discover most of the useful building blocks, combining them into effectiveagentic systems for massive real-world applications would still be challenging and time-consuming,given the many different ways the building blocks can combine and interact with each other. In contrast, with ADAS, the building blocks and agents can be learned in an automated fashion. ADAS may not only potentially save human effort in developing powerful agents but also could be a fasterpath to more effective solutions than manual design. 

Although a few existing works can be considered as ADAS methods, most of them focus only ondesigning prompts (Fernando et al., 2024; Yang et al., 2024), greatly limiting their ability to invent flexible design patterns in agents (Section 5). In this paper, we show that there is an unexploredyet promising approach to ADAS where we can define the entire agentic system in code and newagents can be automatically discovered by a “meta” agent programming even better ones in code.Given that most programming languages, such as Python, which we use in this paper, are TuringComplete (Boyer & Moore, 1983; Ladha, 2024), searching within a code space theoretically enables a ADAS algorithm to discover any possible agentic systems, including all components such as prompts, tool use, control flows, and more. Furthermore, with recent FMs being increasingly proficient incoding, we can use FMs as a meta agent to create new agents in code for ADAS, enabling novel agentsto be programmed in an automated manner.

Following the aforementioned ideas, we present Meta Agent Search in this paper as one of the firstalgorithms in ADAS that enables complete design in code space (Figure 1). The core concept of MetaAgent Search is to instruct a meta agent to iteratively create interestingly new agents, evaluate them,add them to an archive that stores discovered agents, and use this archive to help the meta agent insubsequent iterations create yet more interestingly new agents. Similar to existing open-endednessalgorithms that leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a),we encourage the meta agent to explore interesting (e.g., novel or worthwhile) agents. To validatethe proposed approach, we evaluate the proposed Meta Agent Search on: (1) the challenging ARClogic puzzle task (Chollet, 2019) that aims to test the general intelligence of an AI system, (2) fourpopular benchmarks on reading comprehension, math, science questions, and multi-task problemsolving, and (3) the transferability of discovered agents to held-out domains and models (Section 4). 

Our experiments show that the discovered agents substantially outperform state-of-the-art hand-designed baselines. For instance, our agents improve F1 scores on reading comprehension tasks inDROP (Dua et al., 2019) by 13.6/100 and accuracy rates on math tasks in MGSM (Shi et al., 2023) by 14.4%. Additionally, they improve accuracy over baselines by 25.9% and 13.2% on GSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2023) math tasks, respectively, after transferring across domains. The promising performance of our algorithm over hand-designed solutions illustrates the potential of ADAS in automating the design of agentic systems. Furthermore, the experimentsdemonstrate that the discovered agents not only perform well when transferring across similar domains but also exhibit strong performance when transferring across dissimilar domains, such asfrom mathematics to reading comprehension. This highlights the robustness and transferability of theagentic systems discovered by Meta Agent Search. In conclusion, our work opens up many excitingresearch directions and encourages further studies (Section 6). 

## 2. New Research Area: Automated Design of Agentic Systems (ADAS) 
At the time of writing, the community has not reached a consensus on the definitions or terminologiesof agents. Here, by agents we refer to agentic systems that involve Foundation Models (FMs) as modules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterativesteps of processing (Chase, 2024; Ng, 2024). 
In this paper, we propose a new research area Automated Design of Agentic Systems (ADAS). Similar to research areas in AI-GAs (Clune, 2019) and AutoML (Hutter et al., 2019), such as Neural Architecture Search (Elsken et al., 2019), we formulate ADAS as an optimization process and identifythree key components of ADAS algorithms (Figure 2). 

- Search Space: The search space defines which agentic systems can be represented and thus discovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate onlythe text prompts of an agent, but their other components, such as control flow, remain the same.Thus, in these search spaces, agents that have a different control flow than the predefined one cannot be represented. Existing works also explore search spaces such as graph structures (Zhuge et al., 2024) and feed-forward networks (Liu et al., 2023). 

- Search Algorithm: The search algorithm defines how ADAS algorithms explore the search space.Since the search space is often very large or even unbounded, the exploration-exploitation trade-off (Sutton & Barto, 2018) should be considered. Ideally, the algorithm can both quickly discover high-performance agentic systems and avoid remaining stuck in a local optimum. Existing approaches include using Reinforcement Learning (Zhuge et al., 2024) or an FM iteratively generating new solutions (Fernando et al., 2024) as search algorithms. 

- Evaluation Function: Depending on the application of the ADAS algorithm, we may considerdifferentobjectivestooptimize,suchasperformance,cost,latency,orsafetyofagents. Anevaluationfunction defines how to evaluate a candidate agent on those objectives. For example, to assessthe agent’s performance on unseen future data, a simple method is to calculate the accuracy rateon the validation data for a task, which is commonly adopted in existing works (Fernando et al., 2024; Zhuge et al., 2024). 

Figure 2 |The three key components of Automated Design of Agentic Systems (ADAS). The search space determines which agentic systems can be represented in ADAS. The search algorithm specifieshow the ADAS method explores the search space. The evaluation function defines how to evaluate acandidate agent on target objectives such as performance. 
Formulation 
Automated Design of Agentic Systems (ADAS) involves using a search algorithm to discover agentic systems across a search space that optimize an evaluation function. 


Although many search space designs are possible and some have already been explored (Section 5),there is an unexplored yet promising approach where we can define the entire agentic system incode and new agents can be automatically discovered by a meta agent programming even betterones in code. Searching within a code space theoretically enables the ADAS algorithm to discover any possible building blocks (e.g., prompts, tool use, control flow) and agentic systems that combineany of these building blocks in any way. This approach also offers better interpretability for agentdesign patterns since the program code is often readable, making debugging easier and enhancing AIsafety. Additionally, compared to search spaces using networks (Liu et al., 2023) or graphs (Zhuge et al., 2024), searching in a code space allows us to more easily build on existing human efforts. Forexample, it is possible to search within open-source agent frameworks like LangChain (LangChainAI, 2022) and build upon all existing building blocks (e.g., RAG, search engine tools). Finally, since FMs are proficient in coding, utilizing a code search space allows us to leverage existing expertise fromFMs during the search process. In contrast, search algorithms in custom search spaces, such as graphs,may be much less efficient due to the absence of these priors. Therefore, we argue that the approachof using programming languages as the search space should be studied more in ADAS. 

## 3. Our Algorithm: Meta Agent Search 
In this section, we present Meta Agent Search, a simple yet effective algorithm to demonstrate theapproach of defining and searching for agents in code. The core idea of Meta Agent Search is to adoptFMs as meta agents to iteratively program interestingly new agents based on an ever-growing archiveof previous discoveries. Although any possible building blocks and agentic systems can theoreticallybe programmed by the meta agent from scratch, it is inefficient in practice to avoid providing themeta agent any basic functions such as FM query APIs or existing tools. Therefore, in this paper, wedefine a simple framework (within 100 lines of code) for the meta agent, providing it with a basicset of essential functions like querying FMs or formatting prompts. As a result, the meta agent onlyneeds to program a “forward” function to define a new agentic system, similar to the practice in FunSearch (Romera-Paredes et al., 2024). This function takes in the information of the task andoutputs the agent’s response to the task. Details of the framework codes and examples of the agentsdefined with this framework can be found in Appendix B.

As shown in Figure 1, the core idea of Meta Agent Search is to have a meta agent iterativelyprogram new agents in code. We show the main prompt for the meta agent to program new agentsbelow, where variables in the prompts are highlighted. Similar to existing open-endedness algorithmsthat leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a), we encourage the meta agent to explore interestingly new (e.g., novel or worthwhile) agents based on an ever-growing archive of previous discoveries. We also adopt self-reflection (Madaan et al., 2024; Shinn et al., 2023) iterations in our meta agent, where it performs two iterations of refinement on the novelty and correctness of the proposal and performs up to three refinements when errors occur while running the code. Full details of the prompt are presented in Appendix A.

After a new agent is generated, we evaluate it using the validation data from the target domain.Here, we calculate the performance (e.g., success rate or F1 score) and 95% bootstrap confidenceinterval as the metrics for the meta agent to maximize. The generated agent is then added to thearchive with the evaluation metrics, and the iteration continues with the updated archive until themaximum number of iterations is reached. 

** Main prompt for the meta agent. **
> You are an expert machine learning researcher testing different agentic systems. 
>
> # Your task You are deeply familiar with prompting techniques and the agent works from the literature. Your goal isto maximize the performance by proposing interestingly new agents ...... Use the knowledge from the archive and inspiration from academic literature to propose the next interesting agentic system design. 

## 4. Experiments 
We conduct extensive experiments on: (1) the challenging ARC logic puzzle task (Chollet, 2019)(Section 4.1), (2) four popular benchmarks assessing the agent’s abilities on reading comprehension,math, science questions, and multi-task problem solving (Section 4.2), (3) the transferability of the discovered agents on ARC to three held-out models, and (4) the transferability of discovered agents on Math to four held-out math tasks and three tasks that are beyond math (Section 4.3).Across all experiments, we find that the discovered agents substantially outperform baseline state-of-the-art hand-designed agents. Notably, our discovered agents improve over baselines on readingcomprehension tasks in DROP (Dua et al., 2019) by 13.6/100 (F1 score) and on math tasks in MGSM (Shi et al., 2023) by 14.4% (accuracy rate). Additionally, our discovered agents improve over the baseline on ARC tasks by 14% (accuracy rate) after transferring from GPT-3.5 to GPT-4, and by 25.9% and 13.2% (accuracy rate) after transferring from MGSM math tasks to held-out math tasks in GSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2023) respectively. All code, prompts, and experiment results are available at https://github.com/ShengranHu/ADAS. 

(a) (b) Figure 3 |The results of Meta Agent Search on the ARC challenge. (a) Meta Agent Search progressively discovers high-performance agents based on an ever-growing archive of previous discoveries.We report the median accuracy and the 95% bootstrap confidence interval on a held-out test set byevaluating agents five times. (b) The visualization of the best agent discovered by Meta Agent Searchon the ARC challenge. Detailed implementation of this agent is available in Appendix C. 

## 4.1. Case Study: ARC Challenge 
We first demonstrate how Meta Agent Search discovers novel agentic systems and outperforms existingstate-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge (Chollet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their abilityto efficiently acquire new skills. Questions in ARC include (1) showing multiple examples of visualinput-output grid patterns, (2) the AI system learning the transformation rule of grid patterns fromexamples, and (3) predicting the output grid pattern given a test input grid pattern. Since each question in ARC has a unique transformation rule, it requires the AI system to learn efficiently with few-shot examples, leveraging capabilities in number counting, geometry, and topology.

Setup. Following common practice (Greenblatt, 2024), we require the agent to write code for the transformation rule instead of answering directly. We provide tool functions in the framework thatevaluate the generated transformation code. Given the significant challenge that ARC poses to currentAI systems, we sample our data from questions with grid dimensions ≤5 ×5 in the “Public TrainingSet (Easy)”. We sample a validation set and a test set with 20 and 60 questions, respectively, forsearching and testing. We calculate the validation and test accuracy of an agent by assessing it overthe validation and test sets five times to reduce the variance from the stochastic sampling of FMs. Weevaluate all discovered agents on the held-out test set and report the test accuracy in Figure 3. Meta Agent Search runs for 25 iterations and the meta agent uses GPT-4 (OpenAI, 2024), while discovered agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022) to reduce compute cost. More algorithmic details and examples of ARC questions can be found in 
Appendix C. 

Baselines. We compared against five state-of-the-art hand-designed agents: (1) Chain-of-Thought (COT) (Wei et al., 2022), which instructs the agent to output the reasoning before answering toimprove complex problem-solving through intermediate steps; (2) Self-Consistency with Chain-of-Thought (COT-SC) (Wang et al., 2023b), which ensembles multiple parallel answers from COT toproduce a more accurate answer; (3) Self-Refine (Madaan et al., 2024; Shinn et al., 2023), whichallows iterative self-reflection to correct mistakes made in previous attempts; (4) LLM-Debate (Du et al., 2023), which enables different LLMs to debate with each other, leveraging diverse perspectivesto find better answers; (5) Quality-Diversity, a simplified version of Intelligent Go-Explore (Lu et al., 2024c), which produces and ensembles diverse answers to better explore potential solutions. We alsouse all baselines as initial seeds in the archive for Meta Agent Search. More details about baselinescan be found in Appendix E. 

Results and Analysis. As shown in Figure 3a, Meta Agent Search effectively and progressivelydiscovers agents that perform better than state-of-the-art hand-designed baselines. Important breakthroughs are highlighted in the text boxes. As is critical in prior works on open-endedness and AI-GAs(Faldor et al., 2024; Lehman & Stanley, 2011; Wang et al., 2019, 2020; Zhang et al., 2024a), Meta Agent Search innovates based on a growing archive of previous stepping stones. For example, animportant design pattern emerged in iteration 3 where it uses multiple COTs to generate possibleanswers, refines them, and finally ensembles the best answers. This became a crucial stepping stone that subsequent designs tended to utilize. Additionally, the best-discovered agent is shown in Figure 3b, where a complex feedback mechanism is adopted to refine answers more effectively.Careful observation of the search progress reveals that this sophisticated feedback mechanism didnot appear suddenly. Instead, the ideas of incorporating diverse feedback, evaluating for various specific traits (via experts) such as efficiency and simplicity, and simulating human-like feedbackemerged in iterations 5, 11, and 12, respectively. The final mechanism is an innovation based on these three stepping stones. This illustrates that even though these stepping stones did not achievehigh performance immediately upon emergence, later discoveries benefited from these innovationsby combining different stepping stones, resembling crossover in evolution via LLMs (Meyerson et al., 2023). Overall, the results showcase the potential of ADAS and the effectiveness of Meta Agent Searchto progressively discover agents that outperform state-of-the-art hand-designed baselines and inventnovel design patterns through the innovation and combination of various stepping stones. 

4.2. Reasoning and Problem-Solving Domains 
Setup. Next, we investigate the potential of our algorithm to improve the capabilities of agents acrossmath, reading, and reasoning domains. We test Meta Agent Search on four popular benchmarks: (1)DROP (Dua et al., 2019) for evaluating Reading Comprehension; (2) MGSM (Shi et al., 2023) for 
F1 Score Accuracy (%) 
Agent Name 
Reading Comprehension Math Multi-task Science 
State-of-the-art Hand-designed Agents  
Chain-of-Thought (Wei et al., 2022)  64.2 ±0.9  28.0 ±3.1  65.4 ±3.3  29.2 ±3.1  
COT-SC (Wang et al., 2023b)  64.4 ±0.8  28.2 ±3.1  65.9 ±3.2  30.5 ±3.2  
Self-Refine (Madaan et al., 2024)  59.2 ±0.9  27.5 ±3.1  63.5 ±3.4  31.6 ±3.2  
LLM Debate (Du et al., 2023)  60.6 ±0.9  39.0 ±3.4  65.6 ±3.3  31.4 ±3.2  
Step-back Abstraction (Zheng et al., 2023)  60.4 ±1.0  31.1 ±3.2  65.1 ±3.3  26.9 ±3.0  
Quality-Diversity (Lu et al., 2024c)  61.8 ±0.9  23.8 ±3.0  65.1 ±3.3  30.2 ±3.1  
Role Assignment (Xu et al., 2023)  65.8 ±0.9  30.1 ±3.2  64.5 ±3.3  31.1 ±3.1  
Automated Design of Agentic Systems on Different Domains  
Best Agents from Meta Agent Search  79.4 ±0.8  53.4 ±3.5  69.6 ±3.2  34.6 ±3.2  

Table 1 | Performance comparison between Meta Agent Search and state-of-the-art hand-designed agents across multiple domains. Meta Agent Search discovers superior agents comparedto the baselines in every domain. We report the test accuracy and the 95% bootstrap confidenceinterval on held-out test sets. The search is conducted independently for each domain. 
evaluating Math capability under a multi-lingual setting; (3) MMLU (Hendrycks et al., 2021) for evaluating Multi-task Problem Solving; and (4) GPQA (Rein et al., 2023) for evaluating the capability of solving hard (graduate-level) questions in Science. The search is conducted independently withineach domain. Meta Agent Search runs for 30 iterations. The meta agent uses GPT-4 (OpenAI, 2024),while the discovered agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022). More details about datasets and experiment settings can be found in Appendix D. 
Baselines. We adopt all baselines introduced in Section 4.1. Additionally, since the above domainsrequire strong reasoning skills, we include two additional baselines that specifically focus on enhancingthe reasoning capabilities of agents for a more thorough comparison: (1) Step-back Abstraction (Zheng et al., 2023), which instructs agents to first consider the principles involved in solving the task forbetter reasoning; (2) Role Assignment, which assigns different roles to FMs similar to Xu et al. (2023)to obtain better answers. More details about the baselines can be found in Appendix E. 
Results and Analysis. The results across multiple domains demonstrate that Meta Agent Searchcan discover agents that outperform state-of-the-art hand-designed agents (Table 1). We want tohighlight the substantial gap between the learned agents and hand-designed agents in the ReadingComprehension and Math domains, with improvements in F1 scores by 13.6/100 and accuracy rates by 14.4%, respectively. While Meta Agent Search also outperforms baselines in the Multi-task andScience domains, the gap is smaller. We hypothesize that for challenging questions in the Scienceand Multi-task domains, the knowledge in FMs is not sufficient to solve the questions, limiting theimprovement through optimizing agentic systems, which is a problem that will diminish as FMs improve. In contrast, in the Reading Comprehension and Math domains, FMs possess adequateknowledge to solve the questions, and errors could mainly be hallucinations or calculation mistakes,which can be mitigated through well-designed agentic systems, like the ones discovered by MetaAgent Search. Overall, the results across various domains showcase the effectiveness of Meta AgentSearch in searching for agents tailored to specific domains. This could be increasingly useful forsaving human efforts and developing better task-specific agents as we continue to create agents for adiverse set of applications (Wang et al., 2024). 

4.3. Generalization and transferability 


In the previous sections, we illustrated that Meta Agent Search can find effective agents forindividual tasks. In this section, we further demonstrate the transferability and generalizability of thediscovered agents. To show that the invented building blocks and design patterns are generalizable,we conduct experiments on the transferability of the discovered agents. 

Transferability Across Foundation Models. We first transfer discovered agents from GPT-3.5 (OpenAI, 2022) to other FMs on ARC to test whether agents found when performing Meta Agent Searchwith one FM generalize to others. We test the top 3 agents with the best test accuracy evaluated withGPT-3.5 on ARC and then transfer them to three popular models: Claude-Haiku (Anthropic, 2024a),GPT-4 (OpenAI, 2024), and Claude-Sonnet (Anthropic, 2024b). We adopt the same baselines as those used in ARC (Section 4.1) and MGSM (Section 4.2). As shown in Table 2, we observe that the searched agents consistently outperform the hand-designed agents with a substantial gap. Notably,we found that Claude-Sonnet, the most powerful model from Anthropic, performs the best among alltested models, enabling our best agent to achieve nearly 50% accuracy on ARC. 
Transferability Across Domains. Next, we transfer the discovered agent from the MGSM (Math)domain to other math domains to test whether the invented agents can generalize across differentdomains. Similarly, we test the top 3 agents from MGSM and transfer them to (1) four popular mathdomains: GSM8K (Cobbe et al., 2021), GSM-Hard (Gao et al., 2023), SVAMP (Patel et al., 2021),and ASDiv (Miao et al., 2020) and (2) three domains beyond math adopted in Section 4.2. As shown in Table 3, we observe a similar superiority in the performance of Meta Agent Search compared tobaselines. Notably, our agents improve accuracy by 25.9% and 13.2% on GSM8K (Cobbe et al., 2021)and GSM-Hard (Gao et al., 2023), respectively, compared to the baselines. More surprisingly, weobserve that agents discovered in the math domain can be transferred to non-math domains (Table 4).While the performance of agents originally searched in the math domain does not fully match that ofagents specifically designed for the target domains, they still outperform (in Reading Comprehensionand Multi-task) or match (in Science) the state-of-the-art hand-designed agent baselines. These results illustrate that Meta Agent Search can discover generalizable design patterns and agentic systems. 


## 5. Related Work 
Agentic Systems. Researchers develop various building blocks and design patterns for different applications. Important building blocks for agentic systems includes: prompting techniques (Chen et al., 2023a; Schulhoff et al., 2024), chain-of-thought-based planning and reasoning methods (Hu & Clune, 2024; Wei et al., 2022; Yao et al., 2023), reflection (Madaan et al., 2024; Shinn et al., 2023), developing new skills for embodied agents in code (Vemprala et al., 2023; Wang et al., 2023a),external memory and RAG (Lewis et al., 2020; Zhang et al., 2024c), tool use (Nakano et al., 2021; Qu et al., 2024; Schick et al., 2023), assigning FM modules in the agentic system with different roles and enabling them to collaborate (Hong et al., 2023; Qian et al., 2023, 2024; Wu et al., 2023; Xu et al., 2023), and enabling the agent to instruct itself for the next action (Richards, 2023), etc.While the community has invested substantial effort in developing all the above important techniques,this is only a partial list of the discovered building blocks, and many more remain to be uncovered.Therefore, in this paper, we propose a new research area, ADAS, which aims to invent novel buildingblocks and design powerful agentic systems in an automated manner. 

AI-Generating Algorithms and AutoML. Following the lessons learned from the history of machinelearning, research in AI-Generating Algorithms (AI-GAs) (Clune, 2019) and AutoML (Hutter et al., 2019) continually strives to learn more components in AI systems to replace handcrafted ones. There are mainly three pillars in this field: (1) meta-learning architectures, (2) meta-learning the learningalgorithms, and (3) generating effective learning environments and training data (Clune, 2019). For example, Neural Architecture Search (Elsken et al., 2019; Hu et al., 2021; Lu et al., 2019) aims toautomate the design of neural network architectures like convolution, which falls under the first pillar.The second pillar includes works like MAML (Finn et al., 2017) and Meta-RL (Duan et al., 2017; Norman & Clune, 2023; Wang et al., 2016; Zintgraf et al., 2021a,b), which allow “learning to learn”for better sample efficiency, generalizability, and continuous learning of multiple tasks. Additionally,works like POET (Dharna et al., 2020; Wang et al., 2019, 2020) and OMNI-EPIC (Faldor et al., 2024)under the third pillar aim to generate learning environments in an open-ended manner. We believe that the proposed Automated Design of Agentic Systems belongs to both the first and second pillars:Pillar one because ADAS meta-learns the architecture of agentic systems, but also Pillar two becauseagents are proficient in in-context learning, thus ADAS can also be considered as learning to learn, asdemonstrated in the ARC challenge (Section 4.1). 

Additionally, recent AI-GA and AutoML works have incorporated Foundation Models (FMs) towrite code. For example, in FunSearch (Romera-Paredes et al., 2024) and EoH (Liu et al., 2024),FMs write code to discover better optimization algorithms. In DiscoPOP (Lu et al., 2024a), FMs program the loss function for preference learning in FM alignment training (Rafailov et al., 2024).Additionally, Eureka (Ma et al., 2023) and language-to-reward (Yu et al., 2023) enable FMs to write reward functions for reinforcement learning in robotics. Finally, OMNI-EPIC (Faldor et al., 2024)enables FMs to create robotics learning environments by programming in code. Here, we adopt asimilar idea that enables FMs to program new agents in code.

Existing Attempts to ADAS. There are two categories of works that can be considered attempts atADAS in the literature: those that learn better prompts only, and those that learn more componentsin agents than just prompts. Most works fall into the first category: learning prompts only. Works like OPRO (Yang et al., 2024), PromptBreeder (Fernando et al., 2024), and Self-Discover (Zhou et al., 2024a) adopt FMs to automate prompt engineering for agents, primarily focusing on the phrasing ofinstructions in the prompt to enhance the reasoning capability of agents. Thus, the learned prompts are domain-specific and difficult to generalize. Beyond instructions, works like EvoAgent (Yuan et al., 2024) and AgentVerse (Chen et al., 2023b) optimize role definition in the prompt, as assigningpersonas or roles to agents has been shown to be beneficial (Xu et al., 2023). Although tuning promptseffectively improves performance, other important components in agentic systems remain fixed andhand-designed, vastly limiting the space of agents that can be discovered.

There are far fewer attempts in the second category, which involves learning more componentsthan just prompts in agentic systems. Most represent agents as networks or graphs in the searchspace. In these formulations, the FM with a certain prompt is considered a transformation functionfor text on nodes, and the information flow of the text is considered as edges. DyLAN starts with a fully connected feed-forward network and uses FMs to score the response qualityof nodes in each layer to prune the connections. DSPy (Khattab et al., 2024) first generates a setof possible nodes and then optimizes across the Cartesian product of these nodes while optimizingthe few-shot examples for nodes. GPT-Swarm (Zhuge et al., 2024) represents an agentic system ina graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimizethe possible connections between nodes while optimizing the prompt for each node in a separatestage. Although these works allow the learning of control flow (optimizing edges in networks or graphs), many other components, such as whether and which tools to learn or even how many nodesto have, are still not learned, greatly limiting the space of agents that can be discovered. Besideslearning prompts and control flow, AgentOptimizer (Zhang et al., 2024b) learns the tools used in agents, and Agent Symbolic Learning (Zhou et al., 2024b) learns prompts, tools, and control flow together. While Agent Symbolic Learning shares similar motivations to learn more components inagents, it manually designs the search space for each component separately, which may make it aharder search space for search algorithms. In addition, it mainly improves agents based on an existingcomplex agent, without showing the emergence of new design patterns or building blocks. In contrast,our work represents all possible components in code, allowing the search to be easier by leveraginghuman efforts in the existing codebase of agents and FMs’ expertise in coding. We also demonstratehow novel and diverse building blocks and design patterns emerge from a set of basic agent designs,illustrating the potential creativity that can emerge from ADAS. 


6. Discussion and Conclusion 
Safety Considerations. We strongly advise researchers to be aware of the safety concerns when executing untrusted model-generated code in Meta Agent Search and other research involving code generation. While it is highly unlikely that model-generated code will perform overtlymalicious actions in our current settings and with the Foundation Models (FMs) we use, such code maystill act destructively due to limitations in model capability or alignment (Chen et al., 2021; Rokon et al., 2020). Ideally, sandbox environments can be used to safely run untrusted model-generated code (Chen et al., 2021; Yee et al., 2010).

More broadly, research on more powerful AI systems raises the question of whether we shouldbe conducting research to advance AI capabilities at all. That topic clearly includes the proposedAutomated Design of Agentic Systems (ADAS) as a new area in AI-GA research, which could potentiallycontribute to an even faster way to create Artificial General Intelligence (AGI) than the current manualapproach (Clune, 2019). The question of whether and why we should pursue AGI and AI-GA hasbeen discussed in many papers (Bengio et al., 2024; Bostrom, 2002; Clune, 2019; Ecoffet et al., 2020; Yudkowsky et al., 2008), and is beyond the scope of this paper. Specifically as regards ADAS, webelieve it is net beneficial to publish this work. First, this work demonstrates that with the availableAPI access to powerful FMs, it is easy to program powerful ADAS algorithms, and do so without anyexpensive hardware like GPUs. We feel it is beneficial to let the community know such algorithms arepowerful and easy to create, so they can be informed and account for them. Moreover, by sharing thisinformation, we hope to motivate follow-up work into safe-ADAS, such as algorithms that conductADAS safely during both search itself (e.g. not risking running any harmful code) and that refuseto create dishonest, unhelpful, and/or harmful agents. Such an open-source research approach tocreate safe-ADAS could be a better way to create safer AI systems (Caldwell, 2011; Meta, 2024). Onedirection we find particularly promising is to simply ask the Meta Agent Search algorithm to be safeduring training and only create helpful, harmless, honest agents, potentially incorporating ideas suchas Constitutional AI (Bai et al., 2022). 
Future Work. Our work also opens up many future research directions. For example: 
- Higher-order ADAS. Since the meta agent used in ADAS to program new agents in code is alsoan agent, ADAS can become self-referential where the meta agent can be improved through ADASas well. It would be an exciting direction to have a higher order of meta-learning to allow thelearning of the meta agent and even the meta-meta agent, etc. (Lu et al., 2023)

- Seeding ADAS with more existing building blocks. Although we can theoretically allow anycomponents in agentic systems to be programmed from scratch in the code space, it is not efficientin practice. Therefore, it would be interesting to explore ADAS by standing on the shoulders ofexisting human efforts, such as search engine tools, RAG (Lewis et al., 2020), or functions from existing agent frameworks like LangChain (LangChainAI, 2022). Additionally, it is interestingto support multi-modal capabilities (e.g. vision) in FMs or allow different FMs to be available inagentic systems. This will enable the meta agent to choose from different FMs flexibly according tothe difficulty of the instruction and whether data privacy is a priority. 

- Multi-objective ADAS. We only consider one objective (i.e., performance) to optimize in this paper, but in practice, multiple objectives are often considered, such as cost, latency, and robustnessof agentic systems (Hu et al., 2021; Huang et al., 2023). Thus, integrating multi-objective search algorithms (Deb et al., 2002) in ADAS could be promising. 

- Novelty search algorithms. In Meta Agent Search, the design of the search algorithm is relatively simple, focusing solely on exploring interesting new designs. A more careful design of the search algorithm can be a promising future direction. For example, one could incorporate more sophisticated ideas from Quality-Diversity (Cully & Demiris, 2017; Mouret & Clune, 2015),AI-generating (Clune, 2019), and Open-ended Algorithms (Faldor et al., 2024; Stanley & Lehman, 2015; Stanley et al., 2019; Zhang et al., 2024a). One could also include more classic approaches to balance exploration and exploitation (Liu et al., 2024; Sutton & Barto, 2018).

- More intelligent evaluation functions. In this work, we simply evaluate discovered agents on theevaluation set and use the numerical performance results. However, this approach is both expensiveand misses a lot of information. A promising future direction is to enable the meta agent to analyzedetailed running logs during the evaluation, which contain rich information on the failure andsuccess modes for better debugging and improving agentic systems (Zhou et al., 2024b). Also, many tasks involve subjective answer evaluations (Chiang et al., 2024; Lu et al., 2024b) that donot have ground-truth answers. It is also important to design novel evaluation functions in ADASto address these tasks. Finally, in this work, we targeted only one domain during the search. Itwould be interesting to explore whether ADAS algorithms can design even better generalist agentswhen specifically searching for agents capable of performing well across multiple domains. 

- More complex domains. Additionally, we only evaluate Meta Agent Search on single-step QA tasks in this paper. It would be interesting to extend the method to more complex domians, suchas real-world applications involving multi-step interaction with complex environments. 

- Understanding the emergence of complexity from human organizations. Beyond potentiallysaving researchers’ efforts and improving upon the manual design of agentic systems, the researchin ADAS is also scientifically intriguing as it sheds light on the origins of complexity emerging fromhuman organization and society. The agentic system is a machine learning system that operatesprimarily over natural language—a representation that is interpretable to humans and used byhumans in constructing our organization and society. Thus, there is a close connection between agentic systems and human organizations, as shown in works incorporating the organizationalstructure for human companies in agents (Hong et al., 2023) or simulating a human town with agents (Park et al., 2023). Therefore, the study in ADAS may enable us to observe how to createa simple set of conditions and have an algorithm to bootstrap itself from simplicity to producecomplexity in a system akin to human society. 

- Towards a Better Understanding of FMs. Works from Neural Architecture Search (Huang et al., 2023) show that by observing the emerged architecture, we could gain more insights into NeuralNetworks. In this paper, we also gained insights about FMs from the results. For example, thebest agent with GPT-3.5 involves a complex feedback mechanism, but when we transfer to otheradvanced models, the agent with a simpler feedback mechanism but more refinement becomes abetter agent (Section 4.3). This shows that GPT-3.5 may have a worse capability in evaluating andrefining the answers, so it needs a complex feedback mechanism for better refinement, while otheradvanced models benefit more from a simpler feedback mechanism. 


Conclusion. In this paper, we propose a new research problem, Automated Design of Agentic Systems(ADAS), which aims to automatically invent novel building blocks and design powerful agentic systems. We demonstrated that a promising approach to ADAS is to define agents in code, allowing new agentsto be automatically discovered by a “meta” agent programming them in code. Following this idea, we propose Meta Agent Search, where the meta agent iteratively builds on previous discoveries to program interesting new agents. The experiments show that Meta Agent Search consistentlyoutperforms state-of-the-art hand-designed agents across an extensive number of domains, and thediscovered agents transfer well across models and domains. Overall, our work illustrates the potentialof an exciting new research direction toward full automation in developing powerful agentic systemsfrom the bottom up. 


## Supplementary Material 
Table of Contents A Prompts 24 B Framework Code 26 C Experiment Details for ARC Challenge 30 D Experiment Details for Reasoning and Problem-Solving Domains 33 E Baselines 35 F Example Agents 36 G Cost of Experiments 39 

### A. Prompts 
We use the following prompts for the meta agent in Meta Agent Search. Variables in the promptsthat vary depending on domains and iterations are highlighted. All detailed prompts are available at https://github.com/ShengranHu/ADAS.

We use the following system prompt for every query in the meta agent.

##### System prompt for the meta agent. 
> You are a helpful assistant. Make sure to return in a WELL-FORMED JSON object. 
We use the following prompt for the meta agent to design the new agent based on the archive ofpreviously discovered agents. 

#### Main prompt for the meta agent. 
> You are an expert machine learning researcher testing various agentic systems. Your objective is to designbuilding blocks such as prompts and control flows within these systems to solve complex tasks. Your aim is to design an optimal agent performing well on [Brief Description of the Domain].
>
> [Framework Code]
> [Output Instructions and Examples]
> [Discovered Agent Archive] (initialzied with baselines, updated at every iteration)
>
> # Your task
> You are deeply familiar with prompting techniques and the agent works from the literature. Your goal isto maximize the specified performance metrics by proposing interestingly new agents.Observe the discovered agents carefully and think about what insights, lessons, or stepping stones can belearned from them. 
> Be creative when thinking about the next interesting agent to try. You are encouraged to draw inspirationfrom related agent papers or academic papers from other research areas.Use the knowledge from the archive and inspiration from academic literature to propose the next interesting agentic system design.
> THINK OUTSIDE THE BOX. 


The domain descriptions are available in Appendices C and D and the framework code is available in Appendix B. We use the following prompt to instruct and format the output of the meta agent.Here, we collect and present some common mistakes that the meta agent may make in the prompt.We found it effective in improving the quality of the generated code. 

#### Output Instruction and Example. 
> # Output Instruction and Example:
> The first key should be (“thought”), and it should capture your thought process for designing the next function. In the “thought” section, first reason about what the next interesting agent to tryshould be, then describe your reasoning and the overall concept behind the agent design, and finally detail the implementation steps. The second key (“name”) corresponds to the name of your next agent architecture. Finally, the last key (“code”) corresponds to the exact “forward()” function in Python code that you would like to try. You must write COMPLETE CODE in “code”: Your code will be part of the entire project, so please implement complete, reliable, reusable code snippets. 
> Here is an example of the output format for the next agent:
> {“thought”: “**Insights:** Your insights on what should be the next interesting agent. **Overall Idea:** your reasoning and the overall concept behind the agent design. **Implementation:** describe the implementation step by step.”, “name”: “Name of your proposed agent”, “code”: “def forward(self, taskInfo): # Your code here”} 
>
> ## WRONG Implementation examples:
> [Examples of potential mistakes the meta agent may make in implementation]

After the first response from the meta agent, we perform two rounds of self-reflection to make thegenerated agent novel and error-free (Madaan et al., 2024; Shinn et al., 2023). 
Prompt for self-reflection round 1. 

1. 
**Interestingness**: Assess whether your proposed architecture is interesting or innovative comparedto existing methods in the archive. If you determine that the proposed architecture is not interesting,suggest a new architecture that addresses these shortcomings. -Make sure to check the difference between the proposed architecture and previous attempts. -Compare the proposal and the architectures in the archive CAREFULLY, including their actual differencesin the implementation. -Decide whether the current architecture is innovative. -USE CRITICAL THINKING! 

2. 
**Implementation Mistakes**: Identify any mistakes you may have made in the implementation. Review the code carefully, debug any issues you find, and provide a corrected version. REMEMBER checking "## WRONG Implementation examples" in the prompt. 

3. 
**Improvement**: Based on the proposed architecture, suggest improvements in the detailed implementation that could increase its performance or effectiveness. In this step, focus on refining andoptimizing the existing implementation without altering the overall design framework, except if youwant to propose a different architecture if the current is not interesting. -Observe carefully about whether the implementation is actually doing what it is supposed to do. -Check if there is redundant code or unnecessary steps in the implementation. Replace them with effective implementation. -Try to avoid the implementation being too similar to the previous agent. 


And then, you need to improve or revise the implementation, or implement the new proposed architecturebased on the reflection. 
Your response should be organized as follows: 
"reflection": Provide your thoughts on the interestingness of the architecture, identify any mistakes in theimplementation, and suggest improvements."thought": Revise your previous proposal or propose a new architecture if necessary, using the same format as the example response."name": Provide a name for the revised or new architecture. (Don’t put words like "new" or "improved"in the name.)"code": Provide the corrected code or an improved implementation. Make sure you actually implement your fix and improvement in this code. 
Prompt for self-reflection round 2. 
Using the tips in “## WRONG Implementation examples” section, further revise the code.Your response should be organized as follows:Include your updated reflections in the “reflection”. Repeat the previous “thought” and “name”. Updatethe corrected version of the code in the “code” section. 
When an error is encountered during the execution of the generated code, we conduct a reflectionand re-run the code. This process is repeated up to five times if errors persist. Here is the prompt weuse to self-reflect any runtime error: 
1 2 
3 4 5 
6 7 8 9 10 11 
12 13 14 15 16 
Prompt for self-reflection when a runtime error occurs. 

Error during evaluation: 
Carefully consider where you went wrong in your latest implementation. Using insights from previous
attempts, try to debug the current code to implement the same thought. Repeat your previous thought in
“thought”, and put your thinking for debugging in “debug_thought”. 

B. Framework Code 
In this paper, we provide the meta agent with a simple framework to implement basic functions, such as querying Foundation Models (FMs) and formatting prompts. The framework consists of fewer than 100 lines of code (excluding comments). In this framework, we encapsulate every piece of information into a namedtuple Info object, making it easy to combine different types of information (e.g., FM responses, results from tool function calls, task descriptions) and facilitatecommunicationbetweendifferentmodules. Additionally,intheFMmodule,weautomaticallyconstructthe prompt by concatenating all input Info objects into a structured format, with each Info titled byits metadata (e.g., name, author). Throughout the appendix, we renamed some variables in thecode to match the terminologies used in the main text. The full framework code is available at https://github.com/ShengranHu/ADAS. 
Code 1 | The simple framework used in Meta-Agent Search. 
# Named tuple for holding task information Info = namedtuple( ’Info ’, [’name ’, ’author ’, ’content ’, ’ 
iteration _idx ’]) 
# Format instructions for FM response FORMAT _INST = lambda request _keys: f"Reply EXACTLY with the 
following JSON format.\n{str(request _keys)}\nDO NOT MISS ANY 
FIELDS AND MAKE SURE THE JSON FORMAT IS CORRECT!\n" 
# Description of the role of the FM Module 
ROLE _DESC = lambda role: f"You are a {role}." 
@backoff.on _exception(backoff.expo, openai.RateLimitError) def get _json _response _from _gpt(msg, model, system _message, 
temperature ): 
\""" 
Function to get JSON response from GPT model. 
Args : 
-msg (str): The user message. 
17 18 19 
21 22 23 24 
26 27 28 29 
31 32 33 34 
36 37 38 39 
41 42 43 44 
46 47 48 49 
51 52 53 54 
56 57 58 59 
61 62 63 
64 
66 67 68 69 
-model (str): The model to use. -system _message (str): The system message. -temperature (float): Sampling temperature. 
Returns : -dict: The JSON response. \""" 
... return json _dict 
class FM _Module: \""" Base class for an FM module. 
Attributes : -output _fields (list): Fields expected in the output. -name (str): Name of the FM module. -role (str): Role description for the FM module. -model (str): Model to be used. -temperature (float): Sampling temperature. -id (str): Unique identifier for the FM module instance. \""" 
def __init __(self, output _fields: list , name: str , role =’helpful assistant ’, model =’gpt -3.5 -turbo -0125 ’, temperature =0.5) -> None : ... 
def generate _prompt(self, input _infos, instruction) -> str : \""" Generates a prompt for the FM. 
Args : -input _infos (list): List of input information. -instruction (str): Instruction for the task. 
Returns : -tuple: System prompt and user prompt. 
An example of generated prompt: "" You are a helpful assistant. 
# Output Format: Reply EXACTLY with the following JSON format. ... 
# Your Task : You will given some number of paired example inputs and 
outputs. The outputs ... 
### thinking #1 by Chain -of -Thought hkFo (yourself): ... 
# Instruction: Please think step by step and then solve the task by writing 
70 71 72 73 74 75 
76 77 
78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 
94 
95 96 97 98 99 100 101 102 103 104 105 
106 107 
the code . "" \""" 
... return system _prompt , prompt 
def query(self, input _infos: list , instruction, iteration _idx 
=-1) -> list [Info]: \""" Queries the FM with provided input information and 
instruction . 
Args : -input _infos (list): List of input information. -instruction (str): Instruction for the task. -iteration _idx (int): Iteration index for the task. 
Returns : -output _infos (list[Info]): Output information. \""" 
... return output _infos 
def __repr __(self): return f"{self.agent _name} {self.id}" 
def __call __(self, input _infos: list , instruction, iteration _idx = -1): return self.query(input _infos, instruction, iteration _idx = iteration _idx ) 
class AgentSystem: 
def forward(self, taskInfo) -> Union[Info, str ]: \""" Placeholder method for processing task information. 
Args : -taskInfo (Info): Task information. 
R e t u r n s :  
-A n s w e r ( U n i o n [ Info , str ]) : Y ou r F I N A L e i t h e r a n a m e d t u p l e I n fo or a s t r i n g \ """  A n s w e r . for the  R e t u r n a n s w e r .  
pa ss  

With the provided framework, an agent can be easily defined with a “forward” function. Here we show an example of implementing self-reflection using the framework.  
1 2 3  Code 2 | Self-Reflection implementation example def f o r w a r d ( self , t a s k I n f o ) : # I n s t r u c t i o n f or i n i t i a l r e a s o n i n g c o t _ i n i t i a l _ i n s t r u c t i o n = " P l e a s e t h i n k s te p by s te p a n d t he n s o l v e th e t a s k . "  
4 5  # I n s t r u c t i o n f or r e f l e c t i n g on p r e v i o u s a t t e m p t s and f e e d b a c k  

6 
7 
8 9 10 
11 12 13 14 15 16 17 
18 19 20 21 
22 23 24 25 26 27 28 29 
30 
to improve 
cot _reflect _instruction = "Given previous attempts and feedback, 
carefully consider where you could go wrong in your latest attempt. Using insights from previous attempts, try to solve the task better." 
cot _module = FM _Module([ ’thinking ’, ’answer ’], ’Chain -of -Thought ’) 
# Instruction for providing feedback and correcting the answer 
critic _instruction = "Please review the answer above and criticize on where might be wrong. If you are absolutely sure it is correct, output ’True ’ in ’correct ’." critic _module = FM _Module([ ’feedback ’, ’correct ’], ’Critic ’) 
N_max = 5 # Maximum number of attempts 
# Initial attempt 
cot _inputs = [taskInfo] thinking, answer = cot _module(cot _inputs, cot _initial _instruction , 0) 
for i in range (N _max): 
# Get feedback and correct status from the critic 
feedback, correct = critic _module([taskInfo, thinking, answer], critic _instruction , i) if correct.content == ’True ’: break 
# Add feedback to the inputs for the next iteration 
cot _inputs.extend([thinking, answer, feedback]) 
# Reflect on previous attemps and refine the answer 
thinking, answer = cot _module(cot _inputs, cot _reflect _instruction , i + 1) return answer 

Figure 4 | An example task from the ARC challenge (Chollet, 2019). Given the input-output gridexamples, the AI system is asked to learn the transformation rules and then apply these learned rulesto the test grid to predict the final answer. 

C. Experiment Details for ARC Challenge 
An example task from the ARC challenge is shown in Figure 4. In the ARC challenge experiments (Section 4.1), we represent the grids as strings of 2-D arrays, where each color is represented by an integer. We instruct the meta agent to design agents that generate code as solutions rather than directlyoutputting answers. Additionally, we provide two tool functions within the framework: (1) to testwhether the generated code can solve the example grids and (2) to obtain the task’s answer by applyingthe generated code to the test grid. The accuracy rate is calculated by the Exact Match between thereference solution and the predicted answer. The meta agent uses “gpt-4o-2024-05-13” (OpenAI, 2024), while discovered agents and baselines are evaluated using “gpt-3.5-turbo-0125” (OpenAI, 2022) to reduce compute cost. 
The domain description of ARC for the meta agent is shown below: 
Description of ARC for the meta agent. 
Your aim is to find an optimal agent performing well on the ARC (Abstraction and Reasoning Corpus)challenge.In this challenge, each task consists of three demonstration examples, and one test example. Each Example consists of an “input grid” and an “output grid”. Test-takers need to use the transformation rulelearned from the examples to predict the output grid for the test example. 
# An example task from ARC challenge: 
## Task Overview: You will be given some number of paired example inputs and outputs grids. The outputs were producedby applying a transformation rule to the input grids. In addition to the paired example inputs and outputs, there is also one test input without a known output.The inputs and outputs are each “grids”. A grid is a rectangular matrix of integers between 0 and 9(inclusive). Each number corresponds to a color. 0 is black. Your task is to determine the transformation rule from examples and find out the answer, involvingdetermining the size of the output grid for the test and correctly filling each cell of the grid with theappropriate color or number. 
The transformation only needs to be unambiguous and applicable to the example inputs and the testinput. It doesn’t need to work for all possible inputs. Observe the examples carefully, imagine the gridvisually, and try to find the pattern. 
## Examples:### Example 0:input = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,0,0,0,0], [0,0,0,4,5,0,0,0,0], [0,0,0,4,5,4,4,0,0],[0,0,3,3,5,0,0,0,0], [0,0,0,3,5,0,0,0,0], [0,0,0,3,5,3,3,3,0], [0,0,0,3,5,0,0,0,0], [0,0,0,0,5,0,0,0,0],[0,0,0,0,5,0,0,0,0]] output = [[0,0,0,0], [0,0,0,0], [0,0,0,4], [0,0,4,4], [0,0,3,3], [0,0,0,3], [0,3,3,3], [0,0,0,3], [0,0,0,0], [0,0,0,0]] 
### Example 1:input = [[0,0,0,0,5,0,0,0,0], [0,0,0,2,5,0,0,0,0], [0,0,0,2,5,2,6,0,0], [0,0,0,2,5,0,0,0,0],[0,0,0,2,5,2,2,2,0], [0,0,6,6,5,6,0,0,0], [0,0,0,2,5,0,0,0,0], [0,2,2,0,5,2,0,0,0], [0,0,0,2,5,0,0,0,0],[0,0,0,0,5,0,0,0,0]] output = [[0,0,0,0], [0,0,0,2], [0,0,6,2], [0,0,0,2], [0,2,2,2], [0,0,6,6], [0,0,0,2], [0,2,2,2], [0,0,0,2], [0,0,0,0]] 
### Example 2:input = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,7,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0],[0,7,8,8,5,0,0,0,0], [0,0,0,0,5,8,8,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,0,5,8,7,0,0],[0,0,0,0,5,0,0,0,0]]output= [[0,0,0,0], [0,0,0,7], [0,0,0,8], [0,0,0,8], [0,7,8,8], [0,0,8,8], [0,0,0,8], [0,0,0,8], [0,0,7,8],[0,0,0,0]] 
### Test Problem: input = [[0,0,0,0,5,0,0,0,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,0,0,0], [0,1,1,1,5,1,1,1,6],[0,0,0,6,5,6,6,0,0], [0,0,0,0,5,1,1,1,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,6,0,0], [0,0,0,0,5,6,0,0,0],[0,0,0,0,5,0,0,0,0]] 
Analyze the transformation rules based on the provided Examples and determine what the output shouldbe for the Test Problem. 
Here we present the best agent on ARC discovered by Meta Agent Search. All agents from theexperiment can be found at https://github.com/ShengranHu/ADAS. 
Code 3 | The best agent on ARC discovered by Meta Agent Search 
1 
# Structured Feedback and Ensemble Agent 
2 
def forward(self, taskInfo): 
3 
# Step 1: Generate initial candidate solutions using multiple FM Modules 
4 
5 6 
7 8 9 10 
11 12 
13 
14 
15 16 
17 
18 
19 20 21 
22 23 24 25 
26 
27 
28 
29 30 31 32 33 
34 35 36 37 38 
39 40 
initial _instruction = ’Please think step by step and then solve the task by writing the code.’ 
num _candidates = 5 # Number of initial candidates initial _module = [FM _Module([ ’thinking ’, ’code ’], ’Initial Solution ’, temperature =0.8) for _ in range (num _candidates)] 
initial _solutions = [] for i in range (num _candidates): thoughts = initial _module[i]([taskInfo], initial _instruction 
) thinking, code = thoughts[0], thoughts[1] feedback, correct _examples, wrong _examples = self. 
if  r u n _ e x a m p l e s _ a n d _ g e t _ f e e d b a c k ( co d e ) len ( c o r r e c t _ e x a m p l e s ) > 0: # O n l y c o n s i d e r s o l u t i o n s th a t p a s s e d at l e a s t o ne e x a m p l e i n i t i a l _ s o l u t i o n s . a p p e n d ({ ’ t h i n k i n g ’ : t hi n ki ng , ’ c od e ’ : code , ’ f e e d b a c k ’ : f e ed b a c k , ’ c o r r e c t _ c o u n t ’ : l en ( c o r r e c t _ e x a m p l e s ) })  
#  St ep  2:  S i m u l a t e  human -l i k e  f e e d b a c k  for  e a ch  c a n d i d a t e  

solution 
human _like _feedback _module = FM _Module([ ’thinking ’, ’feedback ’], ’Human -like Feedback ’, temperature =0.5) human _feedback _instruction = ’Please provide human -like feedback for the code , focusing on common mistakes , heuristic corrections , and best practices.’ 
for sol in initial _solutions: thoughts = human _like _feedback _module([taskInfo, sol[ ’ 
thinking ’], sol[ ’code ’]], human _feedback _instruction) human _thinking, human _feedback = thoughts[0], thoughts[1] sol[ ’human _feedback ’] = human _feedback 
# Step 3: Assign expert advisors to evaluate and provide targeted feedback 
expert _roles = [’Efficiency Expert ’, ’Readability Expert ’, ’ Simplicity Expert ’] expert _advisors = [FM _Module([ ’thinking ’, ’feedback ’], role, temperature =0.6) for role in expert _roles] expert _instruction = ’Please evaluate the given code and provide targeted feedback for improvement.’ 
for sol in initial _solutions: sol _feedback = {} for advisor in expert _advisors: 
thoughts = advisor([taskInfo, sol[ ’thinking ’], sol[ ’code 
’]], expert _instruction) thinking, feedback = thoughts[0], thoughts[1] sol _feedback[advisor.role] = feedback 
sol[ ’expert _feedback ’] = sol _feedback 
# Step 4: Parse and structure the feedback to avoid redundancy and refine the solutions iteratively 
max _refinement _iterations = 3 refinement _module = FM _Module([ ’thinking ’, ’code ’], ’Refinement Module ’, temperature =0.5) 
41 42 43 44 45 
46 
47 
48 
49 
50 
51 52 
53 54 55 
56 
57 
58 59 
60 
61 
62 
63 
64 65 
refined _solutions = [] 
for sol in initial _solutions: for i in range (max _refinement _iterations): combined _feedback = sol[ ’feedback ’].content + sol[ ’ human _feedback ’].content + ’’ .join([fb.content for fb in sol[ ’expert _feedback ’].values()]) structured _feedback = ’ ’.join( set (combined _feedback. split())) # Avoid redundancy refinement _instruction = ’Using the structured feedback , refine the solution to improve its performance.’ 
thoughts = refinement _module([taskInfo, sol[ ’thinking ’], sol[ ’code ’], Info( ’feedback ’, ’Structured Feedback ’, structured _feedback , i)], refinement _instruction , i) 
refinement _thinking , refined _code = thoughts[0], thoughts [1] feedback , correct _examples , wrong _examples = self. run _examples _and _get _feedback ( refined _code ) if len (correct _examples) > 0: sol.update({ ’thinking ’: refinement _thinking , ’code ’: refined _code, ’feedback ’: feedback, ’ correct _count ’: len (correct _examples)}) refined _solutions . append (sol) 
# Step 5: Select the best -performing solutions and make a final decision using an ensemble approach 
sorted _solutions = sorted (refined _solutions , key =lambda x: x[ ’ correct _count ’], reverse =True) top _solutions = sorted _solutions [:3] # Select the top 3 solutions 
final _decision _instruction = ’Given all the above solutions , reason over them carefully and provide a final answer by writing the code.’ 
final _decision _module = refinement _module([ ’thinking ’, ’code ’], ’Final Decision Module ’, temperature =0.1) 
final _inputs = [taskInfo] + [item for solution in top _solutions for item in [solution[ ’thinking ’], solution[ ’code ’], solution [’feedback ’]]] 
final _thoughts = final _decision _module(final _inputs, final _decision _instruction) final _thinking , final _code = final _thoughts[0], final _thoughts 
[1] answer = self.get _test _output _from _code(final _code) return answer 

D. Experiment Details for Reasoning and Problem-Solving Domains 
To reduce costs during search and evaluation, we sample subsets of data from each domain. For GPQA(Science), the validation set consists of 32 questions, while the remaining 166 questions form thetest set. For the other domains, the validation and test sets are sampled with 128 and 800 questions,respectively. We evaluate agents five times for GPQA and once for the other domains to maintain aconsistent total number of evaluations. Each domain uses zero-shot style questions, except DROP(Reading Comprehension), which uses one-shot style questions following the practice in (OpenAI, 2023). The meta agent uses “gpt-4o-2024-05-13” (OpenAI, 2024), while discovered agents and baselines are evaluated using “gpt-3.5-turbo-0125” (OpenAI, 2022) to reduce compute cost. 
We present the description of each domain we provide to the meta agent. 
Description of DROP (Reading Comprehension). 
Your aim is to find an optimal agent performing well on the Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs (DROP), which assesses the ability to perform discretereasoning and comprehend detailed information across multiple paragraphs. 
## An example question from DROP: 
You will be asked to read a passage and answer a question. 
Passage:Non-nationals make up more than half of the population of Bahrain, with immigrants making up about 55% of the overall population. Of those, the vast majority come from South and Southeast Asia:according to various media reports and government statistics dated between 2005-2009 roughly 290,000Indians, 125,000 Bangladeshis, 45,000 Pakistanis, 45,000 Filipinos, and 8,000 Indonesians. 
Question: What two nationalities had the same number of people living in Bahrain between 2005-2009? Answer [Not Given]: Pakistanis and Filipinos 
Description of GPQA (Science) for the meta agent. 
Your aim is to find an optimal agent performing well on the GPQA (Graduate-Level Google-Proof Q&ABenchmark). This benchmark consists of challenging multiple-choice questions across the domains ofbiology, physics, and chemistry, designed by domain experts to ensure high quality and difficulty. 
## An example question from GPQA: 
Two quantum states with energies E1 and E2 have a lifetime of 10−9 sec and 10−8 sec, respectively. We want to clearly distinguish these two energy levels. Which one of the following options could be theirenergy difference so that they be clearly resolved? 
Answer choices: 10−9 eV 10−8 eV 10−7 eV 10−6 eV 
Correct answer [Not provided]:10−7 eV 
Explanation [Not provided]:According to the uncertainty principle, Delta E* Delta t=hbar/2. Delta t is the lifetime and Delta E is thewidth of the energy level. With Delta t=10−9 s==> Delta E1= 3.3 10−7 ev. And Delta t=10−11 s gives Delta E2=3.310−8 eV. Therefore, the energy difference between the two states must be significantly greater than 10−7 ev. So the answer is 10−4 ev. 
Description of MGSM (Math) for the meta agent. 
Your aim is to find an optimal agent performing well on the Multilingual Grade School Math Benchmark(MGSM) which evaluates mathematical problem-solving abilities across various languages to ensure broad and effective multilingual performance. 
## An example question from MGSM: 
**Question**:この数学の問題を解いてください。
近所では、ペットのウサギの数がペットの犬と猫を合わせた数よりも 12匹少ない。犬1匹あたり 2匹の猫がおり、犬の数は60匹だとすると、全部で近所には何匹のペットがいますか？ 
**Answer (Not Given)**: 348 
Description of MMLU (Mult-task) for the meta agent. 
Your aim is to find an optimal agent performing well on the MMLU (Massive Multitask LanguageUnderstanding) benchmark, a challenging evaluation that assesses a model’s ability to answer questions across a wide range of subjects and difficulty levels. It includes subjects from STEM, social sciences,humanities, and more. 
## An example question from MMLU: 
Answer the following multiple-choice question. 
The constellation ... is a bright W-shaped constellation in the northern sky. 
(A) Centaurus
(B) Cygnus
(C) Cassiopeia
(D) Cepheus 


E. Baselines 
In this paper, we implement five state-of-the-art hand-designed agent baselines for experimentson ARC (Section 4.1): (1) Chain-of-Thought (COT) (Wei et al., 2022), (2) Self-Consistency with Chain-of-Thought (COT-SC)(Wang et al., 2023b), (3) Self-Refine (Madaan et al., 2024; Shinn et al., 2023), (4) LLM-Debate (Du et al., 2023), and (5) Quality-Diversity, a simplified version of Intelligent Go-Explore (Lu et al., 2024c). 
In addition to these baselines, we implement two more for experiments on Reasoning and Problem-Solving domains (Section 4.2): (6) Step-back Abstraction (Zheng et al., 2023) and (7) Role Assignment (Xu et al., 2023). An example implementation of Self-Refine with our simple framework is shown in Appendix B. Detailed implementations of all baselines can be found at https://github.com/ShengranHu/ADAS. 
In COT, we prompt the FM to think step by step before answering the question. In COT-SC, we sample 𝑁 = 5 answers and then perform an ensemble using either majority voting or an FM query.In Self-Refine, we allow up to five refinement iterations, with an early stop if the critic deems theanswer correct. In LLM-Debate, each debate module is assigned a unique role, such as Physics Expertor Chemistry Expert, and the debate lasts for two rounds. In Quality-Diversity, we conduct three 
1 2 
3 
4 
5 
6 7 
8 
9 
10 11 12 13 14 15 16 
17 18 19 20 21 22 23 
24 25 
iterations to collect diverse answers based on previously proposed ones. In Role Assignment, we usean FM query to first choose a role from a predefined set, and then use another FM query to answerthe question by acting within the chosen role. 

F. Example Agents 
In this section, we present the detailed implementation of three example discovered agents by MetaAgent Search shown in Figure 1. The “Multi-Step Peer Review Agent” and “Divide and Conquer Agent”were discovered during the search in the Reading Comprehension domain (GPQA) (Rein et al., 2023),while the “Verified Multimodal Agent” was discovered during the search in the Math domain (MGSM)(Shi et al., 2023). All discovered agents can be found at https://github.com/ShengranHu/ADAS. 
Code 4 | Example discovered agent: Multi-Step Peer Review Agent 
def forward(self, taskInfo): initial _instruction = "Please think step by step and then solve the task." 
critique _instruction = "Please review the answer above and provide feedback on where it might be wrong. If you are absolutely sure it is correct, output ’True ’ in ’correct ’." 
refine _instruction = "Given previous attempts and feedback, carefully consider where you could go wrong in your latest attempt. Using insights from previous attempts, try to solve the task better." 
final _decision _instruction = "Given all the above thinking and answers , reason over them carefully and provide a final answer ." 
FM _modules = [FM _module([ ’thinking ’, ’answer ’], ’FM Module ’, role =role) for role in [’Physics Expert ’, ’Chemistry Expert ’, ’Biology Expert ’, ’Science Generalist ’]] critic _modules = [FM _module([ ’feedback ’, ’correct ’], ’Critic ’, role =role) for role in [’Physics Critic ’, ’Chemistry Critic ’, ’Biology Critic ’, ’General Critic ’]] final _decision _module = FM _module([ ’thinking ’, ’answer ’], ’Final Decision ’, temperature =0.1) 
all _thinking = [[] for _ in range (len (FM _modules))] all _answer = [[] for _ in range (len (FM _modules))] all _feedback = [[] for _ in range (len (FM _modules))] 
for i in range (len (FM _modules)): thinking, answer = FM _modules[i]([taskInfo], 
initial _instruction) all _thinking [i]. append ( thinking ) all _answer [i]. append ( answer ) 
for i in range (len (FM _modules)): for j in range (len (FM _modules)): if i != j: 
feedback, correct = critic _modules[j]([taskInfo, all _thinking[i][0], all _answer[i][0]], critique _instruction) 
all _feedback [i]. append ( feedback ) 
26 27 28 29 30  for i in r a n g e ( len ( F M _ m o d u l e s ) ) : r e f i n e _ i n p u t s = [ ta s kI nf o , a l l _ t h i n k i n g [ i ][0] , a l l _ a n s w e r [ i ] [ 0 ] ] + a l l _ f e e d b a c k [ i ] th in k in g , a n s w e r = F M _ m o d u l e s [ i ]( r e f i n e _ i n p u t s , r e f i n e _ i n s t r u c t i o n ) a l l _ t h i n k i n g [ i ]. a p p e n d ( t h i n k i n g ) a l l _ a n s w e r [ i ]. a p p e n d ( a n s w e r )  
31  
32 33  f i n a l _ i n p u t s = [ t a s k I n f o ] + [ a l l _ t h i n k i n g [ i ] [ 1] for i in r a n g e ( len ( F M _ m o d u l e s ) ) ] + [ a l l _ a n s w e r [ i ] [1 ] f o r i in r a n g e ( l en ( F M _ m o d u l e s ) ) ] t h in k in g , a n s w e r = f i n a l _ d e c i s i o n _ m o d u l e ( f i n a l _ i n p u t s , f i n a l _ d e c i s i o n _ i n s t r u c t i o n )  
34  
35  r e t u r n a n s w e r  

1 2 3 
4 
5 6 7 
8 
9 10 
11 
12 
13 14 15 
16 17 
18 
19 20 21 22 23 
24 
Code 5 | Example discovered agent: Divide and Conquer Agent 
def forward(self, taskInfo): 
# Step 1: Decompose the problem into sub -problems 
decomposition _instruction = "Please decompose the problem into smaller, manageable sub -problems. List each sub -problem clearly ." 
decomposition _module = FM _Module([ ’thinking ’, ’sub _problems ’], ’ Decomposition Module ’) 
# Step 2: Assign each sub -problem to a specialized expert 
sub _problem _instruction = "Please think step by step and then solve the sub -problem." 
specialized _experts = [FM _Module([ ’thinking ’, ’sub _solution ’], ’ Specialized Expert ’, role =role) for role in [’Physics Expert ’ , ’Chemistry Expert ’, ’Biology Expert ’, ’General Expert ’]] 
# Step 3: Integrate the sub -problem solutions into the final answer 
integration _instruction = "Given the solutions to the sub problems , integrate them to provide a final answer to the 
original problem." 
integration _module = FM _Module([ ’thinking ’, ’answer ’], ’ Integration Module ’, temperature =0.1) 
# Decompose the problem 
thinking, sub _problems = decomposition _module([taskInfo], decomposition _instruction) 
# Ensure sub _problems is a string and split into individual sub problems 
sub _problems _list = sub _problems.content.split( ’\n’ ) if isinstance (sub _problems.content, str ) else [] 
# Solve each sub -problem 
sub _solutions = [] for i, sub _problem in enumerate (sub _problems _list): sub _problem _info = Info( ’sub _problem ’, decomposition _module. __repr __(), sub _problem, i) sub _thinking, sub _solution = specialized _experts[i % len ( 
25 26 27 28 29 
30 31 
1 2 
3 
4 5 6 
7 8 
9 
10 11 
12 
13 
14 
15 16 17 18 
19 20 21 
22 23 24 
25 
specialized _experts )]([ sub _problem _info ], sub _problem _instruction) sub _solutions . append ( sub _solution ) 
# Integrate the sub -problem solutions 
integration _inputs = [taskInfo] + sub _solutions thinking, answer = integration _module(integration _inputs, integration _instruction) 
return answer 
Code 6 | Example discovered agent: Verified Multimodal Agent 
def  f o r w a r d ( self ,  t a s k I n f o ) :  
#  I n s t r u c t i o n  f or  g e n e r a t i n g  v i s u a l  r e p r e s e n t a t i o n  of  the  
p r o b l e m  
v i s u a l _ i n s t r u c t i o n  =  " P l e a s e  c r e a t e  a  v i s u a l  r e p r e s e n t a t i o n ( e . g  
. ,  di ag ram ,  g r a p h )  of  the  g i v e n  p r o b l e m . "  

# Instruction for verifying the visual representation 
verification _instruction = "Please verify the accuracy and relevance of the visual representation. Provide feedback suggestions for improvement if necessary." 
# Instruction for solving the problem using the verified aid 
cot _instruction = "Using the provided visual representation, think step by step and solve the problem." 
# Instantiate the visual representation module , verification module, and Chain -of -Thought module 
visual _module = FM _Module([ ’visual ’], ’Visual Representation Module ’) verification _module = FM _Module([ ’feedback ’, ’verified _ ’Verification Module ’) cot _module = FM _Module([ ’thinking ’, ’answer ’], ’Chain -of -Thought Module ’) 
# Generate the visual representation of the problem 
visual _output = visual _module([taskInfo], visual _instruction) visual _representation = visual _output[0] # Using Info directly 
# Verify the visual representation 
feedback, verified _visual = verification _module([taskInfo, visual _representation], verification _instruction) 
# Use the verified visual representation to solve the 
thinking, answer = cot _module([taskInfo, verified _visual], cot _instruction) return answer 
and 
visual 
visual ’], 
object 
problem 

G. Cost of Experiments 
A single run of search and evaluation on ARC (Section 4.1) costs approximately $500 USD in OpenAIAPI costs, while a run within the reasoning and problem-solving domains (Section 4.2) costs about $300 USD. 
The primary expense comes from querying the “gpt-3.5-turbo-0125” model during the evaluationof discovered agents. Notably, the latest GPT-4 model, “gpt-4o-mini,” is less than one-third the priceof “gpt-3.5-turbo-0125” and offers better performance, suggesting that we could achieve improvedresults with Meta Agent Search at just one-third of the cost. Additionally, as discussed in Section 6, the current naive evaluation function is both expensive and overlooks valuable information. We anticipatethat future work adopting more sophisticated evaluation functions could significantly reduce the costof ADAS algorithms. 



